{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# For custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7059 - accuracy: 0.5010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 0.6955 - accuracy: 0.5190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 313us/step - loss: 0.6896 - accuracy: 0.5210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 286us/step - loss: 0.6863 - accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 0.6837 - accuracy: 0.5550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.6802 - accuracy: 0.5630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 360us/step - loss: 0.6764 - accuracy: 0.5690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 226us/step - loss: 0.6740 - accuracy: 0.5790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 347us/step - loss: 0.6695 - accuracy: 0.6080\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 724us/step - loss: 0.6672 - accuracy: 0.6030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb4903a57d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3414 - accuracy: 0.1110\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 161us/step - loss: 2.3417 - accuracy: 0.0910\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 163us/step - loss: 2.3198 - accuracy: 0.0980\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 2.3291 - accuracy: 0.1100\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 177us/step - loss: 2.3130 - accuracy: 0.1110\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 2.3064 - accuracy: 0.1100\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 149us/step - loss: 2.3068 - accuracy: 0.1210\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 161us/step - loss: 2.3012 - accuracy: 0.1320\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 2.3118 - accuracy: 0.0970\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 181us/step - loss: 2.3075 - accuracy: 0.1100\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 2.2950 - accuracy: 0.1260\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 233us/step - loss: 2.3021 - accuracy: 0.1180\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 2.2993 - accuracy: 0.1140\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 2.3041 - accuracy: 0.1090\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 2.2918 - accuracy: 0.1270\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 2.2976 - accuracy: 0.1110\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 2.2935 - accuracy: 0.1220\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 145us/step - loss: 2.2969 - accuracy: 0.1100\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 2.2928 - accuracy: 0.1400\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 125us/step - loss: 2.2937 - accuracy: 0.1150\n",
      "100/100 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,154\n",
      "Trainable params: 6,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_9 to have shape (1,) but got array with shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-abe28b1f86cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_9 to have shape (1,) but got array with shape (10,)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 0s 0us/step\n",
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/60\n",
      "200285/200285 [==============================] - 398s 2ms/step - loss: 1.9825\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" il contemple les\n",
      "choses d'une maniere d\"\n",
      " il contemple les\n",
      "choses d'une maniere deser to the free and a string and the strength the precession of the possibility of the man and a streaks and the precession of the precession of the precession of the precessed to the processed to the precession of the precessed and a still, and the precession of the precession of the precession of the precessed of the precession of the precession of the precession of the precession of the preces\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" il contemple les\n",
      "choses d'une maniere d\"\n",
      " il contemple les\n",
      "choses d'une maniere distind to be one in the strength of the precession, as a the wand of the man and\n",
      "herigorous of the strange of the can as has life is the free\n",
      "of the truents of the precessions san as the most be life for the precession it exerition of\n",
      "the for the himself to the still, and endiped of the precession of the ear this feeling, a despece of the grathers and power deselfe--in order a still of the speated\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" il contemple les\n",
      "choses d'une maniere d\"\n",
      " il contemple les\n",
      "choses d'une maniere dof about \"in they the\n",
      "faintessions., the\n",
      ".oy concervatione, to a  frielduots\n",
      "comstirans,\n",
      "by this\n",
      "other missinged of the creaturied to the ased, prease\n",
      "it its a panted\n",
      "or its and beta; respected,\n",
      "but regere in held, step thunging\n",
      "one caneaseg and read sheed in noteforforishom paun allever--way respect haf to love that the belieg, for its\n",
      "ever to gobly mace, infoun or man\"\n",
      "to beanberous onelves\n",
      "and \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" il contemple les\n",
      "choses d'une maniere d\"\n",
      " il contemple les\n",
      "choses d'une maniere dangw distentived. as overain also uur is acr hes,\n",
      "dementer-its loveteriogs. new other -agound weak to the gotarssor,, in stoun baly to eurnevicies thome yo its the fruthdencion,s uswan his \"i starty, a smelible is dimve and who menous powity lon\n",
      "strubging blow\" it\n",
      "tol astert tyrave? in mible--it hand us law peronge\"\n",
      "will apprrdous of setuods that cosrowented\n",
      "in \"nay, toudey, as duct bees peective \n",
      "Epoch 2/60\n",
      "200285/200285 [==============================] - 395s 2ms/step - loss: 1.6235\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ies his qualities, such as\n",
      "public spirit\"\n",
      "ies his qualities, such as\n",
      "public spirit and conception of the strength of the strength of the strict of the so the soul to all and stranger of the some strively and the strength of the strint of the strively and stringle of the soult and not the belief of the strance of the procosition to the subjection of the soul and the procossiation of the strength the subject of the strance of the tracted to the sentiment and stringle of the stran\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ies his qualities, such as\n",
      "public spirit\"\n",
      "ies his qualities, such as\n",
      "public spiritual to the all that the strance to under to the sigrice to the more to the from the plofound of sanver to the subject of the precisely recall, that it is to use to the plance and trause of from the strength and belief of the belief and to the great the come also the courally sense and the corcenting of the seem to his conception and always conception of the concerned of all ascertion and asperitio\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ies his qualities, such as\n",
      "public spirit\"\n",
      "ies his qualities, such as\n",
      "public spirits--to the haf many, orper with ll impurse\n",
      "it wishey that y men with an\n",
      "ever toouther once\n",
      "served\n",
      "is every only rebeling body ourselve of be curtion of so been a the one ihalitious and \"trantinand it the maniftrage as as futier, this superstient is to him, where would underit but like are on at a a god of virw the upons, that he anking o  concemply\n",
      "spartion, unilapolour upon hisself them would one \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ies his qualities, such as\n",
      "public spirit\"\n",
      "ies his qualities, such as\n",
      "public spirit to another to resence and wherether ; the phenombes, priituration: late\n",
      "masters\n",
      "that composity of begen to citually huss such reman madir anda!eble and it?\n",
      "unysely like sta\n",
      "limine sedual in evereth. eluvourdet whimself bill could bornckent of alont, the agrine, styir edari wusl\n",
      "ccassimebre--great is it_ please.\n",
      "\n",
      "2kn a a purpliaus lason upoc"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
